from .base_agent import BaseAgent
from agent_prompts.manager_agent import SYSTEM_PROMPT, INPUT_PROMPT_Part_2, INPUT_PROMPT_Part_3
from typing import Dict, Any, Literal
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, BaseMessage
import json
from llm.model import get_llm, get_llm_groq
from llm.config import ManagerConfig
from langgraph.types import Command
from langgraph.graph import END
import re

mac = ManagerConfig()

class ManagerAgent(BaseAgent):
    def __init__(self):
        super().__init__()
        self.model = get_llm(mac.MODEL, mac.TEMPERATURE)
        self.model_alt = get_llm_groq(mac.ALT_MODEL, mac.ALT_TEMPERATURE, mac.ALT_TOP_P, mac.ALT_TOP_K)
        self.system_prompt = SYSTEM_PROMPT

    def format_input_prompt(self, state: Dict[str, Any]) -> str:
        input_prompt = ""
        current_task = state.get('current_task', {})
        task_list = state.get('task_list', [])

        if state.get('previous_messages') and not state.get('current_task'):
            input_prompt += f"The Latest User Query may be based on the previous queries and their responses generated by collaboration of Agents. So use these Q&A as context to generate latest tasks.\n"
            # input_prompt += f"The Latest User Query may be based on the previous queries. So use them as context to handle the latest query.\n"
            msg_hist = "\n".join([f"- Query: {msg[0]}\n- Response: {msg[1]}\n" for msg in state['previous_messages']])
            input_prompt += f"Here is the list of messages from oldest to latest:\n{msg_hist}\n\n"

        input_prompt += f"### Latest User Query: {state['user_query']}\n\n"

        if state.get('initial_info'):
            input_prompt += f"The following is the information obtained from Internal DB:\n{state['initial_info']}\n\nYou have to generate tasks to obtain only the remaining information.\n\n"

        if state.get('task_list'):
            task_list = state.get('task_list')
            input_prompt += f"\n\n- Following are the previously completed and analyzed task without their responses.\n\n"
            for task in task_list:
                agent_task = task.get('agent_task', '')
                agent_name = task.get('agent_name', '')
                task_name = task.get('task_name', '')
                analysis_result = task.get('analysis_result', '')

                input_prompt += (
                    f"Task Name: {task_name}\n"
                    f"Agent Name: {agent_name}\n"
                    f"Agent Task: {agent_task}\n"
                    f"Analysis Result: {analysis_result}\n"
                )

        if state.get('current_task'):
            agent_task = current_task.get('agent_task', '')
            agent_name = current_task.get('agent_name', '')
            task_name = current_task.get('task_name', '')

            if current_task.get('task_messages'):
                task_messages = current_task.get('task_messages')
                if isinstance(task_messages, (list, tuple)) and isinstance(task_messages[-1], BaseMessage):
                    task_response = task_messages[-1].content
                elif isinstance(task_messages, dict):
                    task_response = json.dumps(task_messages)
                else:
                    task_response = str(task_messages)
                input_prompt += f"\n\n- This is the immediate previous task that needs to be analyzed.\n\n"
                input_prompt += (
                    f"Task Name: {task_name}\n"
                    f"Agent Name: {agent_name}\n"
                    f"Agent Task: {agent_task}\n"
                    f"Agent Response:\n{task_response}\n\n"
                )

        # if state.get('validation_result'):
        #     input_prompt += f"- Feedback from Previous Attempt: {state['validation_result']['feedback']}\n"

        #     if state.get('subtasks'):
        #         input_prompt += f"- This is the previously generated subtasks: {state['subtasks']}\n"

        #     input_prompt += INPUT_PROMPT_Part_3
        input_prompt += f"\n{state['user_metadata']}\n"

        return input_prompt

    def extract_thinking_and_json(self, response_content):
        # Extract content between <think> tags
        think_match = re.search(r'<think>(.*?)</think>', response_content, re.DOTALL)
        thinking_process = think_match.group(1).strip() if think_match else "No thinking process found"
        
        # Remove the thinking section from the response to avoid matching JSON inside it
        response_without_thinking = re.sub(r'<think>.*?</think>', '', response_content, flags=re.DOTALL)
        
        # Extract JSON content from the remaining response
        json_match = re.search(r'```json\s*(.*?)\s*```', response_without_thinking, re.DOTALL)
        json_content = json_match.group(1).strip() if json_match else None

        # Try to parse the JSON
        json_dict = None
        if json_content:
            try:
                json_dict = json.loads(json_content)
            except json.JSONDecodeError as e:
                print(f"JSON parsing error: {str(e)}")
                print("Raw JSON content:")
                print(json_content)

        return thinking_process, json_dict

    def __call__(self, state: Dict[str, Any]) -> Dict[str, Any] | Command[Literal["Web Search Agent", "Social Media Scrape Agent", "Finance Data Agent", "Coding Agent", "Response Generator Agent", "__end__"]]:
        input_prompt = self.format_input_prompt(state)
        system_message = SystemMessage(content=self.system_prompt)
        human_message = HumanMessage(content=input_prompt)

        try:
            response = self.model.invoke(input=[system_message, human_message])
        except Exception as e:
            print(f"Falling back to alternate model: {str(e)}")
            try:
                response = self.model_alt.invoke(input=[system_message, human_message])
            except Exception as e:
                print(f"Error occurred in fallback model: {str(e)}")
                raise e

        thinking, task_json = self.extract_thinking_and_json(response.content)

        updated_state = {
            "manager_instructions": [AIMessage(thinking)],
            "messages": [human_message, response],
        }
        
        # print("+"*20, input_prompt, "+"*20, response.content, "+"*20)

        if task_json:
            required_fields = ["task_name", "agent_name", "instructions"]
            if all(field in task_json for field in required_fields):
                # Format task details in the expected structure
                task_details = {
                    "task_name": task_json["task_name"],
                    "agent_name": task_json["agent_name"].replace("_", " "),
                    "agent_task": task_json["agent_task"],
                    "instructions": task_json.get("instructions", ""),
                    "expected_output": task_json.get("expected_output", ""),
                    "required_context": task_json.get("required_context", [])
                }

                # If we have a current task, add it to the task list
                if state.get('current_task') is not None:
                    current_task = state.get('current_task')
                    if task_json.get('prev_task_analysis'):
                        current_task['analysis_result'] = task_json.get('prev_task_analysis')
                    task_messages = current_task.get('task_messages')

                    if isinstance(task_messages, (list, tuple)) and isinstance(task_messages[-1], BaseMessage):
                        task_response = task_messages[-1]
                    elif isinstance(task_messages, dict):
                        task_response = AIMessage(content=json.dumps(task_messages))
                    else:
                        task_response = AIMessage(content=str(task_messages))

                    if task_messages:
                        current_task['task_messages'] = [task_response]
                    updated_state["task_list"] = state.get("task_list", []) + [current_task]

                # Return command to route to the appropriate agent
                return Command(
                    goto=task_details['agent_name'],
                    update={
                        **updated_state,
                        "current_task": task_details,
                    }
                )
        else:
            return Command(goto=END)
